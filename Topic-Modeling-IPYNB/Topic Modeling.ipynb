{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Topic Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Latent Dirichlet Allocation (LDA)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA    \n",
    "- LDA allows us to analyze large amount of data by clustering documents into topics.\n",
    "- This data is unlabeled in general.\n",
    "- LDA is based on the probability distribution i.e it gives out the probability of document belonging to topic1, topic2 and so on.\n",
    "- And probability of word belonging to topic1, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (11992, 1) \n",
      "\n",
      "Columns of dataframe: Index(['Article'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv('05-Topic-Modeling/npr.csv')\n",
    "\n",
    "print('Shape of the dataframe:', df.shape, '\\n\\nColumns of dataframe:', df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the datafame:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  In the Washington of 2016, even when the polic...\n",
       "1    Donald Trump has used Twitter  —   his prefe...\n",
       "2    Donald Trump is unabashedly praising Russian...\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4  From photography, illustration and video, to d..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Head of the datafame:\\n')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- Dataset has only one column 'Article'.\n",
    "- Since there is no label to this dataset, we now will try to create a label.\n",
    "- We will try to create a label with one of the Top Modelling's technique 'Latent Dirichlet Allocation' (LDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check if there any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11992 entries, 0 to 11991\n",
      "Data columns (total 1 columns):\n",
      "Article    11992 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- There are no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the mean, minimum and maximum length of the text for every data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Minimum length of the text: 59\n",
      "\n",
      "Maximum length of the text: 54078\n",
      "\n",
      "Mean length of the text: 4537\n"
     ]
    }
   ],
   "source": [
    "l = df.Article.apply(lambda x: len(x))\n",
    "\n",
    "print('\\nMinimum length of the text:', l.min())\n",
    "print('\\nMaximum length of the text:', l.max())\n",
    "print('\\nMean length of the text:', int(l.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- From the minimum, maximum and mean length of the text data, we can analyze that all the text data contains enought text data to convey an information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FYI:\n",
    "\n",
    " - __As our objective is only to understand the basic application of LDA for topic modelling, I am not doing any Exploratory Data Analysis part.__\n",
    " - __In addition to above, I am not doing data preprocessing such as lemmatization or stemming, punctuation remove, etc.__\n",
    " - __One can do Exploratory Data Analysis, data preprocessing, etc, to get the better understanding of the data, and for the better result.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's print random one data point\n",
    "\n",
    "# random.seed(5)\n",
    "\n",
    "# print('-> Length of the article:', len(df.Article[0]))\n",
    "# print('\\n->', df.Article[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of the text data with TFIDF\n",
    "- One can use other vectorization technique such as Bag of Words, Word2Vec, Average Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the sparse matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing TFIDF vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# creating an instance\n",
    "tf = TfidfVectorizer(max_df = 0.90, min_df = 2, stop_words = 'english')\n",
    "\n",
    "# fit and transform the text data\n",
    "tf_fit = tf.fit_transform(df.Article)\n",
    "\n",
    "print('\\nShape of the sparse matrix\\n')\n",
    "tf_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "- Here, I have set few parameters in TFIDF vectorizer.\n",
    "- max_df is set to 0.90 which means while building a vocabulary, it will not consider those vocabulary words that has the frequency of more than 90% across the documents.\n",
    "- min_df is set to 2 (integet value or you can give float value ranging from 0.0 to 1.0) which means while building a vocabulary, it will not consider those vocabulary words that has the frequency in less than 2 documents i.e vocabulary should occur in at least 2 documents.\n",
    "- Removing stopwords by mentioning stop_words as 'english'\n",
    "- You can play around with the hyperparameters mentioned above or even other hyperparameters like ngram_range, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Latent Dirichlet Allocation (LDA)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Latent Dirichlet Allocation library\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# creating an instance for LDA\n",
    "lda = LatentDirichletAllocation(n_components = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the sparse matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nShape of the sparse matrix\\n')\n",
    "tf_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (404289, 1) \n",
      "\n",
      "Columns of dataframe: Index(['Question'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dft = pd.read_csv('05-Topic-Modeling/quora_questions.csv')\n",
    "\n",
    "print('Shape of the dataframe:', dft.shape, '\\n\\nColumns of dataframe:', dft.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
